---
---

@article{ssd,
abbr = {VLDB},
author = {Kakaraparthy, Aarati and Patel, Jignesh M. and Park, Kwanghyun and Kroth, Brian P.},
title = {Optimizing Databases by Learning Hidden Parameters of Solid State Drives},
year = {2019},
issue_date = {December 2019},
publisher = {VLDB Endowment},
volume = {13},
number = {4},
issn = {2150-8097},
url = {https://doi.org/10.14778/3372716.3372724},
doi = {10.14778/3372716.3372724},
abstract = {Solid State Drives (SSDs) are complex devices with varying internal implementations, resulting in subtle differences in behavior between devices. In this paper, we demonstrate how a database engine can be optimized for a particular device by learning its hidden parameters. This can not only improve an application's performance, but also potentially increase the lifetime of the SSD. Our approach for optimizing a database for a given SSD consists of three steps: learning the hidden parameters of the device, proposing rules to analyze the I/O behavior of the database, and optimizing the database by eliminating violations of these rules.We obtain two different characteristics of an SSD, namely the request size profile and the location profile, from which we learn multiple internal parameters. Based on these parameters, we propose rules to analyze the I/O behavior of a database engine. Using these rules, we uncover sub-optimal I/O patterns in SQLite3 and MariaDB when running on our experimental SSDs. Finally, we present three techniques to optimize these database engines: (1) use-hot-locations on SSD-S, which improves the SELECT operation throughput of SQLite3 and MariaDB by 29% and 27% respectively; it also improves the performance of YCSB on MariaDB by 1%-22% depending on the workload mix, (2) write-aligned-stripes on SSD-T, reduces the wear-out caused by SQLite3 write-ahead log (WAL) file by 3.1%, and (3) contain-write-in-flash-page on SSD-T, which reduces the wear-out caused by the MariaDB binary log file by 6.7%.},
journal = {Proc. VLDB Endow.},
month = dec,
pages = {519â€“532},
numpages = {14}
}

@inproceedings{oneaccess,
abbr = {HotCloud},
author = {Kakaraparthy, Aarati and Venkatesh, Abhay and Phanishayee, Amar and Venkataraman, Shivaram},
title = {The Case for Unifying Data Loading in Machine Learning Clusters},
year = {2019},
publisher = {USENIX Association},
address = {USA},
abstract = {Training machine learning models involves iteratively fetching and pre-processing batches of data. Conventionally, popular ML frameworks implement data loading within a job and focus on improving the performance of a single job. However, such an approach is inefficient in shared clusters where multiple training jobs are likely to be accessing the same data and duplicating operations. To illustrate this, we present a case study which reveals that for hyper-parameter tuning experiments, we can reduce up to 89% I/O and 97% pre-processing redundancy.Based on this observation, we make the case for unifying data loading in machine learning clusters by bringing the isolated data loading systems together into a single system. Such a system architecture can remove the aforementioned redundancies that arise due to the isolation of data loading in each job. We introduce OneAccess, a unified data access layer and present a prototype implementation that shows a 47.3% improvement in I/O cost when sharing data across jobs. Finally we discuss open research challenges in designing and developing a unified data loading layer that can run across frameworks on shared multi-tenant clusters, including how to handle distributed data access, support diverse sampling schemes, and exploit new storage media.},
booktitle = {Proceedings of the 11th USENIX Conference on Hot Topics in Cloud Computing},
pages = {12},
numpages = {1},
location = {Renton, WA, USA},
series = {HotCloud'19}
}
